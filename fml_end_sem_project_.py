# -*- coding: utf-8 -*-
"""FML END SEM PROJECT .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s4tG66UpAmE18k8OMIGPpmgFc0c5UU_4

#Imports
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge
from sklearn.linear_model import Lasso
from sklearn.linear_model import ElasticNet
from sklearn.model_selection import train_test_split

"""#Importing file"""

df = pd.read_csv(r"essel_csv_26.csv")
df.dataframeName = 'essel_csv_26.csv'

"""#Shape of the data
(no.of rows and  columns)
"""

nRow, nCol = df.shape
print(f'There are {nRow} rows and {nCol} columns')

"""#Description of data"""

df.describe()

"""#Printing the names of the columns"""

df.columns

"""#Printing a column"""

df['water_sports']

"""#Printing first 5 rows"""

df.head (5)

"""#Printing last 5 rows"""

df.tail(5)

"""#Checking for null values"""

df.isnull().sum()

"""Here we didn't get any null values.so,now we can proceed with the values

#Information of the data
"""

df.info()

"""#Descriptive analysis

#Column distribution
"""

def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):

    df = df[[col for col in df ]] #for defining the col funtion

    columnNames = list(df)
    nGraphRow = int((nCol + nGraphPerRow - 1) / nGraphPerRow)
    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')
    for i in range(min(nCol, nGraphShown)):
        plt.subplot(nGraphRow, nGraphPerRow, i + 1)
        columnDf = df.iloc[:, i]
        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):
            valueCounts = columnDf.value_counts()
            valueCounts.plot.bar()
        else:
            columnDf.hist()
        plt.ylabel('counts')
        plt.xlabel(f'{columnNames[i]}')
        plt.xticks(rotation = 90)
        plt.title(f'{columnNames[i]} (column {i})')
    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)
    plt.show()

plotPerColumnDistribution(df,8,5)

"""#Scatter plot"""

def plotScatterMatrix(df, plotSize, textSize):

    # Remove rows and columns that would lead to df being singular
    df = df.dropna('columns')
    df = df[[col for col in df ]] # keep columns where there are more than 1 unique values
    columnNames = list(df)

    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')

    plt.suptitle('Scatter Plot')
    plt.show()

plotScatterMatrix(df, 35, 15)

"""#Correlation table"""

df.corr()

"""#Correlation graph"""

sns.heatmap(df.corr(), annot=True)

"""#Recomendations
we can see that the hygine has a correlation between 0.5 to 1 with nearly all the events which proves that hygine is one of the deciding factor.
So, i would recommend them to keep the place more hygienic.

we can also see ferris_wheel also has nearly same values this indicates that the ferris_wheel is one of the main attractions in the theme park therefore they can proceed to imporve the ferris_wheel with maybe some more lights and some more attractive changes to improve the sales.

#Linear Regression
"""

X = df[['kids_count', 'travel_kms', 'water_sports', 'ferris_wheel', 'long_lines', 'hygeine']]
y = df['will_reco']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = LinearRegression().fit(X_train, y_train)

model.score(X_train,y_train)

lin_reg = LinearRegression()

lin_reg.fit(X, y)

lin_reg.intercept_, lin_reg.coef_

lin_reg.predict(X_train)

"""#Ridge regression"""

rdg = Ridge(alpha=1.0)
rdg.fit(X_train,y_train)
print('Coefficients: ', rdg.coef_)
print('Variance score: {}'.format(rdg.score(X_test, y_test)))

"""#Lasso  regression"""

lasso_reg = Lasso(alpha=1.0)
lasso_reg.fit(X_train,y_train)
print('Coefficients: ', lasso_reg.coef_)
print('Variance score: {}'.format(lasso_reg.score(X_test, y_test)))

"""#Elastic regression"""

elasticmodel2 = ElasticNet(alpha=1.0, l1_ratio=0.5)
elasticmodel2.fit(X, y)
y_pred = elasticmodel2.predict(X_test)
print('Coefficients: ', elasticmodel2.coef_)
print('Variance score: {}'.format(elasticmodel2.score(X_test, y_test)))

"""Here the Elastic model is the best model as the variance score is the best performing model"""